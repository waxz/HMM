{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对应状态集合Q\n",
    "states = ('Healthy', 'Fever')\n",
    "# 对应观测集合V\n",
    "observations = ('normal', 'cold', 'dizzy')\n",
    "# 初始状态概率向量π\n",
    "start_probability = {'Healthy': 0.6, 'Fever': 0.4}\n",
    "# 状态转移矩阵A\n",
    "transition_probability = {\n",
    "    'Healthy': {'Healthy': 0.7, 'Fever': 0.3},\n",
    "    'Fever': {'Healthy': 0.4, 'Fever': 0.6},\n",
    "}\n",
    "# 观测概率矩阵B\n",
    "emission_probability = {\n",
    "    'Healthy': {'normal': 0.5, 'cold': 0.4, 'dizzy': 0.1},\n",
    "    'Fever': {'normal': 0.1, 'cold': 0.3, 'dizzy': 0.6},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Healthy', 1: 'Fever'} {'Healthy': 0, 'Fever': 1}\n",
      "{0: 'normal', 1: 'cold', 2: 'dizzy'} {'normal': 0, 'cold': 1, 'dizzy': 2}\n"
     ]
    }
   ],
   "source": [
    "def generate_index_map(lables):\n",
    "    id2label = {}\n",
    "    label2id = {}\n",
    "    i = 0\n",
    "    for l in lables:\n",
    "        id2label[i] = l\n",
    "        label2id[l] = i\n",
    "        i += 1\n",
    "    return id2label, label2id\n",
    " \n",
    "states_id2label, states_label2id = generate_index_map(states)\n",
    "observations_id2label, observations_label2id = generate_index_map(observations)\n",
    "print(states_id2label, states_label2id)\n",
    "print(observations_id2label, observations_label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_map_to_vector(map_, label2id):\n",
    "    \"\"\"将概率向量从dict转换成一维array\"\"\"\n",
    "    v = np.zeros(len(map_), dtype=float)\n",
    "    for e in map_:\n",
    "        v[label2id[e]] = map_[e]\n",
    "    return v\n",
    "\n",
    " \n",
    "def convert_map_to_matrix(map_, label2id1, label2id2):\n",
    "    \"\"\"将概率转移矩阵从dict转换成矩阵\"\"\"\n",
    "    m = np.zeros((len(label2id1), len(label2id2)), dtype=float)\n",
    "    for line in map_:\n",
    "        for col in map_[line]:\n",
    "            m[label2id1[line]][label2id2[col]] = map_[line][col]\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7 0.3]\n",
      " [0.4 0.6]]\n",
      "[[0.5 0.4 0.1]\n",
      " [0.1 0.3 0.6]]\n",
      "[0.6 0.4]\n"
     ]
    }
   ],
   "source": [
    "A = convert_map_to_matrix(transition_probability, states_label2id, states_label2id)\n",
    "print(A)\n",
    "B = convert_map_to_matrix(emission_probability, states_label2id, observations_label2id)\n",
    "print(B)\n",
    "observations_index = [observations_label2id[o] for o in observations]\n",
    "pi = convert_map_to_vector(start_probability, states_label2id)\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机生成观测序列和状态序列    \n",
    "def simulate(T):\n",
    "\n",
    "    def draw_from(probs):\n",
    "        \"\"\"\n",
    "        1.np.random.multinomial:\n",
    "        按照多项式分布，生成数据\n",
    "        >>> np.random.multinomial(20, [1/6.]*6, size=2)\n",
    "                array([[3, 4, 3, 3, 4, 3],\n",
    "                       [2, 4, 3, 4, 0, 7]])\n",
    "         For the first run, we threw 3 times 1, 4 times 2, etc.  \n",
    "         For the second, we threw 2 times 1, 4 times 2, etc.\n",
    "        2.np.where:\n",
    "        >>> x = np.arange(9.).reshape(3, 3)\n",
    "        >>> np.where( x > 5 )\n",
    "        (array([2, 2, 2]), array([0, 1, 2]))\n",
    "        \"\"\"\n",
    "        return np.where(np.random.multinomial(1,probs) == 1)[0][0]\n",
    "\n",
    "    observations = np.zeros(T, dtype=int)\n",
    "    states = np.zeros(T, dtype=int)\n",
    "    states[0] = draw_from(pi)\n",
    "    observations[0] = draw_from(B[states[0],:])\n",
    "    for t in range(1, T):\n",
    "        states[t] = draw_from(A[states[t-1],:])\n",
    "        observations[t] = draw_from(B[states[t],:])\n",
    "    return observations, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2 0 0 1 0 0 0 2]\n",
      "[1 0 1 0 0 0 1 0 1 1]\n",
      "病人的状态:  ['Fever', 'Healthy', 'Fever', 'Healthy', 'Healthy', 'Healthy', 'Fever', 'Healthy', 'Fever', 'Fever']\n",
      "病人的观测:  ['dizzy', 'normal', 'dizzy', 'normal', 'normal', 'cold', 'normal', 'normal', 'normal', 'dizzy']\n"
     ]
    }
   ],
   "source": [
    "# 生成模拟数据\n",
    "observations_data, states_data = simulate(10)\n",
    "print(observations_data)\n",
    "print(states_data)\n",
    "# 相应的label\n",
    "print(\"病人的状态: \", [states_id2label[index] for index in states_data])\n",
    "print(\"病人的观测: \", [observations_id2label[index] for index in observations_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## offline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(obs_seq):\n",
    "    \"\"\"前向算法\"\"\"\n",
    "    N = A.shape[0]\n",
    "    T = len(obs_seq)\n",
    "    \n",
    "    # F保存前向概率矩阵\n",
    "    F = np.zeros((N,T))\n",
    "    F[:,0] = pi * B[:, obs_seq[0]]\n",
    "\n",
    "    for t in range(1, T):\n",
    "        for n in range(N):\n",
    "            F[n,t] = np.dot(F[:,t-1], (A[:,n])) * B[n, obs_seq[t]]\n",
    "\n",
    "    return F\n",
    "\n",
    "def backward(obs_seq):\n",
    "    \"\"\"后向算法\"\"\"\n",
    "    N = A.shape[0]\n",
    "    T = len(obs_seq)\n",
    "    # X保存后向概率矩阵\n",
    "    X = np.zeros((N,T))\n",
    "    X[:,-1:] = 1\n",
    "#     print(\"x: \", X)\n",
    "\n",
    "    for t in reversed(range(T-1)):\n",
    "        for n in range(N):\n",
    "#             dd = X[:,t+1] * A[n,:] * B[:, obs_seq[t+1]]\n",
    "#             print(dd)\n",
    "            X[n,t] = np.sum(X[:,t+1] * A[n,:] * B[:, obs_seq[t+1]])\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.00000000e-02, 6.90000000e-02, 5.47800000e-03, 5.56770000e-03,\n",
       "        2.20058700e-03, 6.54980136e-04, 2.77587163e-04, 1.03986035e-04,\n",
       "        3.84704668e-05, 2.84262018e-06],\n",
       "       [2.40000000e-01, 1.62000000e-02, 1.82520000e-02, 1.25946000e-03,\n",
       "        2.42598600e-04, 2.41720578e-04, 3.41526388e-05, 1.03767732e-05,\n",
       "        3.74218744e-06, 8.27187151e-06]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(observations_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.72193484e-05, 1.19866304e-04, 6.41945373e-04, 1.73522452e-03,\n",
       "        4.63311200e-03, 1.36959500e-02, 3.70450000e-02, 9.95000000e-02,\n",
       "        2.50000000e-01, 1.00000000e+00],\n",
       "       [3.45055449e-05, 1.75538070e-04, 4.16278486e-04, 1.15389304e-03,\n",
       "        3.78784400e-03, 8.86940000e-03, 2.43400000e-02, 7.40000000e-02,\n",
       "        4.00000000e-01, 1.00000000e+00]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward(observations_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch_train(observations, A, B, pi, criterion=0.05):\n",
    "    \"\"\"无监督学习算法——Baum-Weich算法\"\"\"\n",
    "    n_states = A.shape[0]\n",
    "    n_samples = len(observations)\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        # alpha_t(i) = P(O_1 O_2 ... O_t, q_t = S_i | hmm)\n",
    "        # Initialize alpha\n",
    "        alpha = forward(observations)\n",
    "\n",
    "        # beta_t(i) = P(O_t+1 O_t+2 ... O_T | q_t = S_i , hmm)\n",
    "        # Initialize beta\n",
    "        beta = backward(observations)\n",
    "        # ξ_t(i,j)=P(i_t=q_i,i_{i+1}=q_j|O,λ)\n",
    "        xi = np.zeros((n_states,n_states,n_samples-1))\n",
    "        for t in range(n_samples-1):\n",
    "            denom = np.dot(np.dot(alpha[:,t].T, A) * B[:,observations[t+1]].T, beta[:,t+1])\n",
    "            for i in range(n_states):\n",
    "                numer = alpha[i,t] * A[i,:] * B[:,observations[t+1]].T * beta[:,t+1].T\n",
    "                xi[i,:,t] = numer / denom\n",
    "\n",
    "        # γ_t(i)：gamma_t(i) = P(q_t = S_i | O, hmm)\n",
    "        gamma = np.sum(xi,axis=1)\n",
    "        # Need final gamma element for new B\n",
    "        # xi的第三维长度n_samples-1，少一个，所以gamma要计算最后一个\n",
    "        prod =  (alpha[:,n_samples-1] * beta[:,n_samples-1]).reshape((-1,1))\n",
    "        gamma = np.hstack((gamma,  prod / np.sum(prod))) #append one more to gamma!!!\n",
    "        \n",
    "        # 更新模型参数\n",
    "        newpi = gamma[:,0]\n",
    "        newA = np.sum(xi,2) / np.sum(gamma[:,:-1],axis=1).reshape((-1,1))\n",
    "        newB = np.copy(B)\n",
    "        num_levels = B.shape[1]\n",
    "        sumgamma = np.sum(gamma,axis=1)\n",
    "        for lev in range(num_levels):\n",
    "            mask = observations == lev\n",
    "            newB[:,lev] = np.sum(gamma[:,mask],axis=1) / sumgamma\n",
    "        \n",
    "        # 检查是否满足阈值\n",
    "        if np.max(abs(pi - newpi)) < criterion and \\\n",
    "                        np.max(abs(A - newA)) < criterion and \\\n",
    "                        np.max(abs(B - newB)) < criterion:\n",
    "            done = 1\n",
    "        A[:], B[:], pi[:] = newA, newB, newpi\n",
    "    return newA, newB, newpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi:  [0.4 0.6]\n",
      "newA:  [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "newB:  [[0.28928929 0.2952953  0.41541542]\n",
      " [0.29070929 0.29470529 0.41458541]]\n",
      "newpi:  [0.4 0.6]\n",
      "pi:  [0.4 0.6]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0.5, 0.5],[0.5, 0.5]])\n",
    "B = np.array([[0.3, 0.3, 0.4],[0.3, 0.3, 0.4]])\n",
    "pi = np.array([0.4, 0.6])\n",
    "print(\"pi: \", pi)\n",
    "pic = pi.copy()\n",
    "\n",
    "observations_data, states_data = simulate(200)\n",
    "newA, newB, newpi = baum_welch_train(observations_data, A, B, pic,0.02)\n",
    "print(\"newA: \", newA)\n",
    "print(\"newB: \", newB)\n",
    "print(\"newpi: \", newpi)\n",
    "print(\"pi: \", pi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
